{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "_y-7YYuF3CyQ",
      "metadata": {
        "id": "_y-7YYuF3CyQ"
      },
      "source": [
        "# Setup\n",
        "\n",
        "- Accessing Dataset\n",
        "- Clone Splice code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BfxYeW9M9KRm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfxYeW9M9KRm",
        "outputId": "56cb54d9-bd45-49d6-b69f-179253dadf53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ln: failed to create symbolic link '/content/drive/MyDrive/Thesis/Thesis': File exists\n"
          ]
        }
      ],
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/omerbt/Splice.git"
      ],
      "metadata": {
        "id": "qRq7yvvV79eW"
      },
      "id": "qRq7yvvV79eW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X4fvrNSj__39",
      "metadata": {
        "id": "X4fvrNSj__39"
      },
      "outputs": [],
      "source": [
        "subtrain_image_dir = \"/content/drive/MyDrive/Cat | CATFLW/splitted/subtrain\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mh-bTKw7vq0z",
      "metadata": {
        "id": "Mh-bTKw7vq0z"
      },
      "source": [
        "# ST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S0rrxjnsvwir",
      "metadata": {
        "id": "S0rrxjnsvwir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from Splice.train_v2 import train_model2\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import imghdr\n",
        "import logging\n",
        "import datetime\n",
        "from torchvision.transforms import ToPILImage, Resize\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**overriden functions**"
      ],
      "metadata": {
        "id": "VitGRV1K9QsI"
      },
      "id": "VitGRV1K9QsI"
    },
    {
      "cell_type": "code",
      "source": [
        "#Note save_result & train_model where overriden with few changes\n",
        "\n",
        "# save_result in (util.py) callback was changed to give a special name - based on chosen convention - for image to ease processing them later\n",
        "# Last geenrated image (last epoch was given sufix _final to ease grepping last results)\n",
        "def save_result2(image_t, file_name, dataroot, arg, cfg=None, epoch=0):\n",
        "    extre=\"none\"\n",
        "    now = datetime.now()\n",
        "    timestamp = now.strftime(\"%m_%d_%M\")\n",
        "    if cfg is not None: #anadil_changed\n",
        "        opt = cfg['optimizer']\n",
        "        lrate = cfg['lr']\n",
        "        current_epoch = epoch\n",
        "        epoch = cfg['n_epochs']\n",
        "        extra = opt + \"_\" + str(lrate) + \"_\" + str(current_epoch) + \"_\" + str(epoch)\n",
        "\n",
        "\n",
        "    image = ToPILImage()(image_t)\n",
        "    path = Path(f\"{dataroot}/out\")\n",
        "    merge_images_v2(arg[0], arg[1], image, f\"{path}/{file_name}_{extra}_{timestamp}_v2.png\");\n",
        "    path = Path(f\"{dataroot}/out\")\n",
        "    if epoch == current_epoch:\n",
        "        print(\"Saving Last Image, Yahooo!\");\n",
        "        image.save(f\"{path}/{file_name}_{timestamp}_final.png\")\n",
        "    else:\n",
        "        image.save(f\"{path}/{file_name}_{timestamp}.png\")\n",
        "\n",
        "\n",
        "\n",
        "def train_model2(dataroot, image_name, config, callback=None, arg=None): # Added arg to callback function\n",
        "    cfg = config\n",
        "    if dataroot is not None:\n",
        "        cfg['dataroot'] = dataroot\n",
        "    # set seed\n",
        "    seed = cfg['seed']\n",
        "    if seed == -1:\n",
        "        seed = np.random.randint(2**32 - 1)  # Generate seed without dtype\n",
        "        #print(f\"\"Seed value: {seed}, Type: {type(seed)}\"\")  # Debugging line to confirm the type\n",
        "        random.seed(seed)  # Set Python's random seed\n",
        "        np.random.seed(seed)  # Set NumPy's random seed\n",
        "        torch.manual_seed(seed)  # Set PyTorch's random seed\n",
        "        print(f'running with seed: {seed}.')\n",
        "\n",
        "    # create dataset, loader\n",
        "    dataset = SingleImageDataset(cfg)\n",
        "\n",
        "    # define model\n",
        "    model = Model(cfg)\n",
        "\n",
        "    # define loss function\n",
        "    criterion = LossG(cfg)\n",
        "\n",
        "    # define optimizer, scheduler\n",
        "    optimizer = get_optimizer(cfg, model.netG.parameters())\n",
        "\n",
        "    scheduler = get_scheduler(optimizer,\n",
        "                              lr_policy=cfg['scheduler_policy'],\n",
        "                              n_epochs=cfg['n_epochs'],\n",
        "                              n_epochs_decay=cfg['scheduler_n_epochs_decay'],\n",
        "                              lr_decay_iters=cfg['scheduler_lr_decay_iters'])\n",
        "\n",
        "    with tqdm(range(1, cfg['n_epochs'] + 1)) as tepoch:\n",
        "        for epoch in tepoch:\n",
        "            inputs = dataset[0]\n",
        "            for key in inputs:\n",
        "                inputs[key] = inputs[key].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            losses = criterion(outputs, inputs)\n",
        "            loss_G = losses['loss']\n",
        "            log_data = losses\n",
        "            log_data['epoch'] = epoch\n",
        "\n",
        "            # update learning rate\n",
        "            lr = optimizer.param_groups[0]['lr']\n",
        "            log_data[\"lr\"] = lr\n",
        "            tepoch.set_description(f\"Epoch {log_data['epoch']}\")\n",
        "            tepoch.set_postfix(loss=log_data[\"loss\"].item(), lr=log_data[\"lr\"])\n",
        "\n",
        "            # log current generated entire image\n",
        "            if epoch % cfg['log_images_freq'] == 0:\n",
        "                img_A = dataset.get_A().to(device)\n",
        "                with torch.no_grad():\n",
        "                    output = model.netG(img_A)\n",
        "                save_result_v2(output[0],image_name, cfg['dataroot'],arg, cfg, epoch) ##anadil_changed\n",
        "                with open('./st.log', 'a') as f:\n",
        "                    # Append the content\n",
        "                    f.write(\"image_name: {} loss:{:.2f} \\n\".format(image_name, loss_G))\n",
        "                print(f\" current loss_G is {loss_G}\")\n",
        "\n",
        "                if callback is not None:\n",
        "                    callback(output[0])\n",
        "\n",
        "            loss_G.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n"
      ],
      "metadata": {
        "id": "INQbE3lt6aR-"
      },
      "id": "INQbE3lt6aR-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "brgIogcI8P8C",
      "metadata": {
        "id": "brgIogcI8P8C"
      },
      "outputs": [],
      "source": [
        "#Change it to your working directory\n",
        "working_dir = \"/content/drive/MyDrive/Splice\"\n",
        "#The command os.chdir(\"/Splice\") is used to change the current working directory to \"/Splice\".\n",
        "os.chdir(working_dir)\n",
        "\n",
        "DATAROOT = \"./datasets/curr_pair\"\n",
        "path_dataroot = Path(DATAROOT)\n",
        "# if os.path.exists(path_dataroot):\n",
        "#   shutil.rmtree(path_dataroot)\n",
        "dir_a = Path(f\"{DATAROOT}/A\")\n",
        "dir_b = Path(f\"{DATAROOT}/B\")\n",
        "# path_Outimage = Path(f\"{DATAROOT}/out\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output_randomization_file = \"/content/drive/MyDrive/splitted/pairs.json\"  # Replace with your output file path"
      ],
      "metadata": {
        "id": "nRZ30-cy6ARM"
      },
      "id": "nRZ30-cy6ARM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XSB3p1i78K5B",
      "metadata": {
        "id": "XSB3p1i78K5B"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_style_transfer_with_pairs(content_dir, style_dir, pairs, start_index=0):\n",
        "\n",
        "    # Load configuration\n",
        "    with open(\"conf/default/config.yaml\", \"r\") as f:\n",
        "        cfg = yaml.safe_load(f)\n",
        "    cfg['n_epochs'] = 4000  # Adjust the number of epochs if needed\n",
        "    cfg['dataroot'] = './datasets/curr_pair/step5-train1'\n",
        "    max_times = 100\n",
        "    for i, pair in enumerate(pairs[start_index:], start=start_index):\n",
        "        if max_times == i :\n",
        "          return;\n",
        "        content_index = pair['content_index']\n",
        "        content_image = pair['content_image']\n",
        "        style_index = pair['style_index']\n",
        "        style_image = pair['style_image']\n",
        "\n",
        "        selected_image = content_image\n",
        "        random_choice = style_image\n",
        "\n",
        "        print(f\"\\n \\n Starting Style Transfer for Pair {i } - finish at {max_times+1}\")\n",
        "        print(f\"Using content image: {selected_image}\")\n",
        "        print(f\"Using style image: {random_choice}\")\n",
        "\n",
        "        # Clear previous images in 'A' and 'B' directories\n",
        "        for f in os.listdir(dir_a):\n",
        "            os.remove(os.path.join(dir_a, f))\n",
        "        for f in os.listdir(dir_b):\n",
        "            os.remove(os.path.join(dir_b, f))\n",
        "\n",
        "        # Prepare paths\n",
        "        content_image_path = os.path.join(content_dir, selected_image)\n",
        "        style_image_path = os.path.join(style_dir, random_choice)\n",
        "        dest_content_image = os.path.join(dir_a, selected_image)\n",
        "        dest_style_image = os.path.join(dir_b, random_choice)\n",
        "\n",
        "        # Copy the images to the directories\n",
        "        shutil.copy(content_image_path, dest_content_image)\n",
        "        shutil.copy(style_image_path, dest_style_image)\n",
        "\n",
        "        def show_img_aux(image_path):\n",
        "            image = tf.keras.preprocessing.image.load_img(image_path)\n",
        "            image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
        "            plt.imshow(image_array.astype('uint8'))\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        # # Display images\n",
        "        show_img_aux(dest_content_image)\n",
        "        show_img_aux(dest_style_image)\n",
        "\n",
        "        # Train model for the pair\n",
        "        output_name = f\"{selected_image}_{random_choice}___{content_index}_{style_index}_output\"\n",
        "        train_model2(\n",
        "            DATAROOT,\n",
        "            output_name,\n",
        "            cfg,\n",
        "            show_result_st,\n",
        "            [dest_style_image, dest_content_image]\n",
        "        )\n",
        "\n",
        "    print(\"Style transfer completed for all specified pairs!\")\n",
        "\n",
        "\n",
        "start_index = 0  # Start processing from index 0 (change as needed)\n",
        "\n",
        "run_style_transfer_with_pairs(subtrain_dirr, subtrain_dirr, pairs, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTYYt-8_9eq3"
      },
      "id": "VTYYt-8_9eq3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}